{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking the current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get the current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    ##Uncomment the code below to check the files retrived.\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8056 rows in the overall list of rows\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print('There are {} rows in the overall list of rows'.format(len(full_data_rows_list)))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6821 rows in the csv file -- including headers\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print('There are {} rows in the csv file -- including headers'.format(sum(1 for line in f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Data Modeling and Inserting Data Into Tables \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "try:\n",
    "    session.execute(\n",
    "        \"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "###Check keyspace creation\n",
    "chk_query='''\n",
    "SELECT * FROM system_schema.tables \n",
    "WHERE keyspace_name = 'sparkify';\n",
    "'''\n",
    "[print(x) for x in session.execute(chk_query)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create tables to support three different data access patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### These are examples of the data access patterns we will use.\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Table Creation process for the first data access pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Ava</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>495.3073</td>\n",
       "      <td>free</td>\n",
       "      <td>New Haven-Milford, CT</td>\n",
       "      <td>338</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist firstName gender  itemInSession  lastName    length level  \\\n",
       "5250  Faithless       Ava      F              4  Robinson  495.3073  free   \n",
       "\n",
       "                   location  sessionId                             song  \\\n",
       "5250  New Haven-Milford, CT        338  Music Matters (Mark Knight Dub)   \n",
       "\n",
       "      userId  \n",
       "5250      50  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Check to see if the test data is in the csv file prior to inserting into table\n",
    "'''\n",
    "df=pd.read_csv('event_datafile_new.csv')\n",
    "df[(df['sessionId']==338)&(df['itemInSession']==4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create first table music_sessionId which supports queries of the music app history by session Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#drop table if exists -- facilitates a clean setup for multiple testing\n",
    "session_table_drop = \"DROP TABLE IF EXISTS music_sessionId\"\n",
    "try:\n",
    "    session.execute(session_table_drop)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "create_query='CREATE TABLE sparkify.music_sessionId '\n",
    "create_query=create_query+ ''' (sessionId int, itemInSession int, artist text, song_title text, song_length decimal, PRIMARY KEY(sessionId, itemInSession))\n",
    "WITH CLUSTERING ORDER BY (itemInSession ASC);''' \n",
    "try:\n",
    "    session.execute(create_query)\n",
    "except Exception as e:\n",
    "        print(e)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Model the data in the csv file and insert into the music_sessionId table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6820 rows in csv\n",
      "Row(count=6820)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Process the csv file to create the first table\n",
    "'''\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "chk=0\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        chk+=1\n",
    "        insert_query = \"INSERT INTO music_sessionId ( itemInSession, sessionId, artist, song_title, song_length)\"\n",
    "        insert_query = insert_query + \"VALUES (%s,%s,%s,%s,%s)\"\n",
    "\n",
    "        session.execute(insert_query,(int(line[3]),int(line[8]),line[0],line[9],float(line[5])))\n",
    "\n",
    "print('{} rows in csv'.format(chk))\n",
    "\n",
    "###Query table to confirm the same number of rows exist there\n",
    "query='''\n",
    "SELECT count(*) FROM music_sessionId;\n",
    "'''\n",
    "\n",
    "rows=session.execute(query)\n",
    "for row in rows:\n",
    "    print(*rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Faithless', 'Music Matters (Mark Knight Dub)', Decimal('495.3073'))\n"
     ]
    }
   ],
   "source": [
    "## Verify the data was entered into the table\n",
    "query='''\n",
    "SELECT artist,song_title,song_length FROM sparkify.music_sessionId WHERE sessionid=338 AND iteminsession=4;\n",
    "'''\n",
    "\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows: \n",
    "    print((row.artist, row.song_title, row.song_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Table Creation Process for the second data access pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6820 rows in csv\n",
      "Row(count=6820)\n",
      "('Down To The Bone', 0, \"Keep On Keepin' On\", 'Sylvie', 'Cruz')\n",
      "('Three Drives', 1, 'Greece 2000', 'Sylvie', 'Cruz')\n",
      "('Sebastien Tellier', 2, 'Kilometer', 'Sylvie', 'Cruz')\n",
      "('Lonnie Gordon', 3, 'Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', 'Sylvie', 'Cruz')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This table suports the data access pattern to find music listened to by a particular user during a specific session\n",
    "'''\n",
    "##CREATE TABLE\n",
    "session_table_drop1 = \"DROP TABLE IF EXISTS artist_song_user\"\n",
    "try:\n",
    "    session.execute(session_table_drop1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "create_query1='CREATE TABLE IF NOT EXISTS artist_song_user '\n",
    "create_query1=create_query1+ ''' (userid int, sessionId int, itemInSession int, artist text, song_title text, firstName text, lastName text, \n",
    "PRIMARY KEY((userid, sessionid),itemInSession))\n",
    "WITH CLUSTERING ORDER BY (itemInSession ASC);''' \n",
    "try:\n",
    "    session.execute(create_query1)\n",
    "except Exception as e:\n",
    "        print(e)                    \n",
    "\n",
    "##INSERT the modeled data into the table\n",
    "file = 'event_datafile_new.csv'\n",
    "chk=0\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        chk+=1\n",
    "        insert_query1 = \"INSERT INTO artist_song_user (userId, sessionId, itemInSession, artist, song_title, firstName, lastName)\"\n",
    "        insert_query1 = insert_query1 + \" VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "\n",
    "        session.execute(insert_query1,\n",
    "                        (int(line[10]), int(line[8]), int(line[3]),line[0], line[9],  line[1], line[4])\n",
    "                       )\n",
    "\n",
    "print('There are {} rows in csv'.format(chk))\n",
    "\n",
    "###Query table to confirm the same number of rows exist there\n",
    "query1='''SELECT count(*) FROM artist_song_user;'''\n",
    "\n",
    "rows=session.execute(query1)\n",
    "for row in rows:\n",
    "    print(*rows)\n",
    "\n",
    "    \n",
    "## Verify the data was entered into the table\n",
    "query='''SELECT artist,iteminsession,song_title,firstname,lastname FROM sparkify.artist_song_user WHERE userid=10 AND sessionid=182;'''\n",
    "\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows: \n",
    "    print((row.artist, row.iteminsession ,row.song_title, row.firstname, row.lastname))                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Table Creation Process for the third data access pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6820 rows in csv\n",
      "Row(count=6618)\n",
      "('All Hands Against His Own', 'Jacqueline', 'Lynch')\n",
      "('All Hands Against His Own', 'Tegan', 'Levine')\n",
      "('All Hands Against His Own', 'Sara', 'Johnson')\n"
     ]
    }
   ],
   "source": [
    "##CREATE TABLE\n",
    "session_table_drop2 = \"DROP TABLE IF EXISTS user_song\"\n",
    "try:\n",
    "    session.execute(session_table_drop2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "create_query2='CREATE TABLE IF NOT EXISTS user_song '\n",
    "create_query2=create_query2+ ''' (song_title text, userId int, firstName text, lastName text, \n",
    "PRIMARY KEY(song_title,userId))\n",
    "WITH CLUSTERING ORDER BY (userId ASC);''' \n",
    "try:\n",
    "    session.execute(create_query2)\n",
    "except Exception as e:\n",
    "        print(e)                    \n",
    "\n",
    "##INSERT modeled data into the table\n",
    "file = 'event_datafile_new.csv'\n",
    "chk=0\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        chk+=1\n",
    "        insert_query2 = \"INSERT INTO user_song (song_title, userId, firstName, lastName)\"\n",
    "        insert_query2 = insert_query2 + \" VALUES (%s,%s,%s,%s)\"\n",
    "\n",
    "        session.execute(insert_query2,\n",
    "                        (line[9], int(line[10]),line[1], line[4])\n",
    "                       )\n",
    "\n",
    "\n",
    "print('There are {} rows in csv'.format(chk))\n",
    "\n",
    "###Query table to confirm the same number of rows exist there\n",
    "query1='''SELECT count(*) FROM user_song;'''\n",
    "\n",
    "rows=session.execute(query1)\n",
    "for row in rows:\n",
    "    print(*rows)\n",
    "\n",
    "    \n",
    "## Verify the data was entered into the table\n",
    "query='''SELECT song_title,firstname,lastname FROM sparkify.user_song WHERE song_title='All Hands Against His Own';'''\n",
    "\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows: \n",
    "    print((row.song_title, row.firstname, row.lastname))       \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<cassandra.cluster.ResultSet at 0x7efbfc0cc588>,\n",
       " <cassandra.cluster.ResultSet at 0x7efbfc049c88>,\n",
       " <cassandra.cluster.ResultSet at 0x7efbfc049fd0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop the table before closing out the sessions\n",
    "drop_query1='''\n",
    "DROP TABLE music_sessionId\n",
    "'''\n",
    "drop_query2='''\n",
    "DROP TABLE artist_song_user\n",
    "'''\n",
    "drop_query3='''\n",
    "DROP TABLE user_song\n",
    "'''\n",
    "drop_tables=[drop_query1,drop_query2,drop_query3]\n",
    "\n",
    "[session.execute(f) for f in drop_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
